import asyncio
import base64
import re
import time
import html
import logging
from datetime import datetime
from io import BytesIO

import httpx
import yaml
from telegram import Update, constants
from telegram.ext import ApplicationBuilder, MessageHandler, filters, ContextTypes

# --- æ—¥å¿—é…ç½® ---
logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.INFO)

# --- é™æ€é…ç½® ---
TOKEN = "ä½ çš„_TELEGRAM_BOT_TOKEN"
REMOTE_MAPPINGS_URL = "https://raw.githubusercontent.com/Hyy800/Quantumult-X/refs/heads/Nana/ymys.txt"
REMOTE_CONFIG_MAPPINGS = {}

# åœ°åŒºè¯†åˆ«è§„åˆ™ (æ¢å¤åŸç‰ˆ)
REGION_RULES = [
    ('é¦™æ¸¯', ['é¦™æ¸¯', 'hong kong', 'hongkong', 'hk', 'hkg']),
    ('å°æ¹¾', ['å°æ¹¾', 'taiwan', 'tw', 'taipei', 'tpe']),
    ('æ—¥æœ¬', ['æ—¥æœ¬', 'japan', 'jp', 'tokyo', 'osaka', 'jap']),
    ('æ–°åŠ å¡', ['æ–°åŠ å¡', 'singapore', 'sg', 'sgp']),
    ('éŸ©å›½', ['éŸ©å›½', 'korea', 'kr', 'seoul', 'kor']),
    ('ç¾å›½', ['ç¾å›½', 'united states', 'us', 'usa', 'los angeles', 'san jose']),
]

# å…¨å±€å¹¶å‘é™åˆ¶
GLOBAL_SEMAPHORE = asyncio.Semaphore(30)
shared_client = httpx.AsyncClient(timeout=httpx.Timeout(15.0), follow_redirects=True)

# --- å·¥å…·å‡½æ•° ---

def format_size(size: float) -> str:
    units = ['B', 'KB', 'MB', 'GB', 'TB', 'PB']
    level = 0
    while size >= 1024 and level < len(units) - 1:
        size /= 1024
        level += 1
    return f"{size:.2f} {units[level]}"

def parse_user_info(header: str):
    info = {}
    for part in header.split(';'):
        if '=' in part:
            k, v = part.split('=', 1)
            info[k.strip().lower()] = v.strip()
    return info

def analyze_regions(proxies):
    """æ¢å¤åŸç‰ˆçš„èŠ‚ç‚¹åœ°åŒºç»Ÿè®¡é€»è¾‘"""
    stats = {}
    for p in proxies:
        name = str(p.get('name', '')).lower()
        found = False
        for region, keywords in REGION_RULES:
            if any(k in name for k in keywords):
                stats[region] = stats.get(region, 0) + 1
                found = True
                break
        if not found:
            stats['å…¶ä»–'] = stats.get('å…¶ä»–', 0) + 1
    
    if not stats: return "æ— æœ‰æ•ˆèŠ‚ç‚¹"
    return " | ".join([f"{k}:{v}" for k, v in stats.items()])

async def get_node_info(url: str):
    """è·å–èŠ‚ç‚¹è¯¦ç»†ä¿¡æ¯åŠç»Ÿè®¡"""
    try:
        resp = await shared_client.get(url)
        data = resp.text
        # Clash æ ¼å¼
        if 'proxies' in data:
            config = yaml.safe_load(data)
            proxies = config.get('proxies', [])
            return {"count": len(proxies), "detail": analyze_regions(proxies)}
        # V2Ray Base64 æ ¼å¼
        try:
            missing_padding = len(data) % 4
            if missing_padding: data += '=' * (4 - missing_padding)
            decoded = base64.b64decode(data).decode('utf-8')
            lines = [l for l in decoded.splitlines() if '://' in l]
            if lines:
                # ç®€å•æ¨¡æ‹Ÿ Base64 èŠ‚ç‚¹åè¯†åˆ«ï¼ˆå¯é€‰ï¼‰
                return {"count": len(lines), "detail": f"{len(lines)}ä¸ªé€šç”¨èŠ‚ç‚¹"}
        except: pass
    except: pass
    return None

async def load_remote_mappings():
    global REMOTE_CONFIG_MAPPINGS
    try:
        resp = await shared_client.get(REMOTE_MAPPINGS_URL)
        for line in resp.text.splitlines():
            if '=' in line and not line.startswith('#'):
                k, v = line.split('=', 1)
                REMOTE_CONFIG_MAPPINGS[k.strip()] = v.strip()
    except Exception as e:
        logging.error(f"åŠ è½½æ˜ å°„å¤±è´¥: {e}")

async def process_sub(url: str):
    async with GLOBAL_SEMAPHORE:
        try:
            headers = {'User-Agent': 'Clash-Verge/1.0.0'}
            resp = await shared_client.get(url, headers=headers)
            if resp.status_code != 200:
                return {"success": False, "url": url, "error": f"HTTP {resp.status_code}"}
            
            user_info = resp.headers.get('subscription-userinfo')
            if not user_info:
                return {"success": False, "url": url, "error": "è¯¥é“¾æ¥ä¸è¿”å›æµé‡ä¿¡æ¯"}
            
            info = parse_user_info(user_info)
            u, d, t, e = int(info.get('upload', 0)), int(info.get('download', 0)), int(info.get('total', 0)), int(info.get('expire', 0))
            
            used = u + d
            percent = round((used / t) * 100, 2) if t > 0 else 0
            name = next((v for k, v in REMOTE_CONFIG_MAPPINGS.items() if k in url), "æœªçŸ¥æœºåœº")
            node = await get_node_info(url)
            
            return {
                "success": True, "url": url, "name": name, "total": t, "used": used,
                "remain": max(0, t - used), "percent": percent, "expire_ts": e,
                "node": node, "up": u, "down": d
            }
        except Exception:
            return {"success": False, "url": url, "error": "è¯·æ±‚è¶…æ—¶"}

# --- æ¶ˆæ¯å¤„ç†å™¨ ---

async def handle_request(update: Update, context: ContextTypes.DEFAULT_TYPE):
    msg = update.effective_message
    if not msg: return

    content = msg.text or msg.caption or ""
    urls = re.findall(r'https?://[^\s]+', content)

    if msg.document and (msg.document.file_name.endswith('.txt') or msg.document.mime_type == 'text/plain'):
        file = await msg.document.get_file()
        byte_content = await file.download_as_bytearray()
        urls.extend(re.findall(r'https?://[^\s]+', byte_content.decode('utf-8', errors='ignore')))

    urls = list(dict.fromkeys(urls))
    if not urls: return

    status_msg = await msg.reply_text("â³ æ­£åœ¨è·å–è®¢é˜…ä¿¡æ¯...")

    tasks = [process_sub(url) for url in urls]
    responses = await asyncio.gather(*tasks)

    results = []
    for res in responses:
        safe_url = html.escape(res['url'])
        if not res["success"]:
            results.append(f"âŒ <b>è§£æå¤±è´¥</b>\né“¾æ¥: <code>{safe_url}</code>\nåŸå› : {res['error']}")
            continue
        
        # æ¢å¤åŸç‰ˆè¿›åº¦æ¡æ’ç‰ˆ
        filled = min(15, int(res['percent'] / 6.6))
        bar = "â–ˆ" * filled + "â–‘" * (15 - filled)
        expire_date = datetime.fromtimestamp(res['expire_ts']).strftime('%Y-%m-%d') if res['expire_ts'] > 0 else "æ°¸ä¹…/æœªçŸ¥"
        
        # æ¢å¤åŸç‰ˆçš„è¾“å‡ºæ¨¡æ¿
        output = (
            f"ğŸ“„ <b>æœºåœºåç§°</b>: <code>{html.escape(res['name'])}</code>\n"
            f"ğŸ·ï¸ <b>è®¢é˜…é“¾æ¥</b>: <code>{safe_url}</code>\n"
            f"ğŸ“Š <b>æµé‡ä¿¡æ¯</b>:\n"
            f"é¢„è§ˆ: <code>[{bar}] {res['percent']}%</code>\n"
            f"æ€»æµé‡: <code>{format_size(res['total'])}</code>\n"
            f"å·²ä½¿ç”¨: <code>{format_size(res['used'])}</code> (â†‘{format_size(res['up'])} â†“{format_size(res['down'])})\n"
            f"å‰©ä½™é‡: <code>{format_size(res['remain'])}</code>\n"
            f"â° <b>åˆ°æœŸæ—¶é—´</b>: <code>{expire_date}</code>\n"
        )
        if res['node']:
            output += f"ğŸŒ <b>èŠ‚ç‚¹ä¿¡æ¯</b>: <code>{res['node']['count']}ä¸ªèŠ‚ç‚¹ ({res['node']['detail']})</code>"
        
        results.append(output)

    # æ¢å¤åŸç‰ˆçš„åˆ†éš”ç¬¦
    final_text = "\n" + ("="*20) + "\n\n".join(results)

    if len(final_text) > 4000:
        clean_text = re.sub('<[^<]+?>', '', final_text)
        bio = BytesIO(clean_text.encode())
        bio.name = "subscription_report.txt"
        await msg.reply_document(document=bio, caption="âœ… ç»“æœå·²ç”Ÿæˆæ–‡ä»¶")
        await status_msg.delete()
    else:
        await status_msg.edit_text(final_text, parse_mode=constants.ParseMode.HTML, disable_web_page_preview=True)

async def main():
    await load_remote_mappings()
    app = ApplicationBuilder().token(TOKEN).concurrent_updates(True).build()
    app.add_handler(MessageHandler(filters.TEXT | filters.Document.Category("text/plain"), handle_request))
    print(">>> å®Œç¾æ ¼å¼å¹¶å‘ç‰ˆå¯åŠ¨æˆåŠŸ...")
    async with app:
        await app.initialize()
        await app.start()
        await app.updater.start_polling()
        await asyncio.Event().wait()

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        pass
