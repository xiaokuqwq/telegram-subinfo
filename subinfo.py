import asyncio
import base64
import re
import time
import io
from datetime import datetime
from io import BytesIO

import httpx
import yaml
from telegram import Update, constants
from telegram.ext import ApplicationBuilder, CommandHandler, ContextTypes

# --- é™æ€é…ç½® ---
TOKEN = "ä½ çš„_TELEGRAM_BOT_TOKEN"
REMOTE_MAPPINGS_URL = "https://raw.githubusercontent.com/Hyy800/Quantumult-X/refs/heads/Nana/ymys.txt"
REMOTE_CONFIG_MAPPINGS = {}
MAX_CONCURRENT_REQUESTS = 5  # æœ€å¤§å¹¶å‘è¯·æ±‚æ•°

# --- å·¥å…·å‡½æ•° ---

def format_size(size: float) -> str:
    units = ['B', 'KB', 'MB', 'GB', 'TB', 'PB']
    level = 0
    while size >= 1024 and level < len(units) - 1:
        size /= 1024
        level += 1
    return f"{size:.2f} {units[level]}"

def parse_user_info(header: str):
    info = {}
    parts = header.split(';')
    for part in parts:
        if '=' in part:
            k, v = part.split('=', 1)
            info[k.strip().lower()] = v.strip()
    return info

async def get_node_info(url: str):
    async with httpx.AsyncClient(timeout=10.0) as client:
        try:
            resp = await client.get(url)
            data = resp.text
            
            # 1. å°è¯• YAML
            try:
                config = yaml.safe_load(data)
                if isinstance(config, dict) and 'proxies' in config:
                    return {"count": len(config['proxies']), "detail": "Clash/Surge"}
            except: pass

            # 2. å°è¯• Base64
            try:
                missing_padding = len(data) % 4
                if missing_padding: data += '=' * (4 - missing_padding)
                decoded = base64.b64decode(data).decode('utf-8')
                lines = [l for l in decoded.splitlines() if '://' in l]
                if lines:
                    return {"count": len(lines), "detail": "V2Ray/SS"}
            except: pass
        except: pass
    return None

async def load_remote_mappings():
    global REMOTE_CONFIG_MAPPINGS
    async with httpx.AsyncClient(timeout=10.0) as client:
        try:
            resp = await client.get(REMOTE_MAPPINGS_URL)
            for line in resp.text.splitlines():
                if '=' in line and not line.startswith('#'):
                    k, v = line.split('=', 1)
                    REMOTE_CONFIG_MAPPINGS[k.strip()] = v.strip()
        except Exception as e:
            print(f"åŠ è½½æ˜ å°„å¤±è´¥: {e}")

# --- æ ¸å¿ƒé€»è¾‘ ---

async def process_sub(url: str, semaphore: asyncio.Semaphore):
    # ä½¿ç”¨ä¿¡å·é‡æ§åˆ¶å¹¶å‘
    async with semaphore:
        headers = {'User-Agent': 'FlClash/v0.8.76 clash-verge'}
        async with httpx.AsyncClient(headers=headers, timeout=15.0, follow_redirects=True) as client:
            try:
                resp = await client.get(url)
                if resp.status_code != 200:
                    return {"success": False, "url": url, "error": f"HTTP {resp.status_code}"}
                
                user_info_raw = resp.headers.get('subscription-userinfo')
                if not user_info_raw:
                    return {"success": False, "url": url, "error": "æ— æµé‡ç»Ÿè®¡ä¿¡æ¯ (Header)"}
                
                info = parse_user_info(user_info_raw)
                upload = int(info.get('upload', 0))
                download = int(info.get('download', 0))
                total = int(info.get('total', 0))
                expire_ts = int(info.get('expire', 0))
                
                used = upload + download
                remain = max(0, total - used)
                percent = round((used / total) * 100, 2) if total > 0 else 0
                
                name = "æœªçŸ¥æœºåœº"
                for k, v in REMOTE_CONFIG_MAPPINGS.items():
                    if k in url:
                        name = v
                        break
                
                node_data = await get_node_info(url)
                
                return {
                    "success": True, "url": url, "name": name, "total": total, "used": used,
                    "remain": remain, "percent": percent, "expire_ts": expire_ts,
                    "node": node_data, "upload": upload, "download": download
                }
            except Exception as e:
                return {"success": False, "url": url, "error": str(e)}

# --- æŒ‡ä»¤å¤„ç†å™¨ ---

async def subinfo_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    msg = update.effective_message
    text = msg.text or msg.caption or ""
    urls = []

    # 1. æå–é“¾æ¥ (å½“å‰æ¶ˆæ¯ã€å½“å‰é™„ä»¶ã€å›å¤çš„æ¶ˆæ¯ã€å›å¤çš„é™„ä»¶)
    urls.extend(re.findall(r'https?://[^\s]+', text))
    
    # è¾…åŠ©å‡½æ•°ï¼šä»æ–‡æ¡£ä¸­è¯»å–é“¾æ¥
    async def extract_from_doc(doc):
        if doc and (doc.file_name.endswith('.txt') or doc.mime_type == 'text/plain'):
            doc_file = await context.bot.get_file(doc.file_id)
            byte_content = await doc_file.download_as_bytearray()
            return re.findall(r'https?://[^\s]+', byte_content.decode('utf-8', errors='ignore'))
        return []

    if msg.document:
        urls.extend(await extract_from_doc(msg.document))

    if msg.reply_to_message:
        reply = msg.reply_to_message
        urls.extend(re.findall(r'https?://[^\s]+', reply.text or reply.caption or ""))
        if reply.document:
            urls.extend(await extract_from_doc(reply.document))

    urls = list(dict.fromkeys(urls))

    if not urls:
        await msg.reply_text("âŒ æœªæ‰¾åˆ°è®¢é˜…é“¾æ¥ã€‚\nå‘é€é“¾æ¥ã€ä¸Šä¼  .txt æ–‡ä»¶æˆ–å›å¤æ–‡ä»¶å³å¯æŸ¥è¯¢ã€‚", parse_mode=constants.ParseMode.MARKDOWN)
        return

    is_txt = "txt" in text.lower()
    status_msg = await msg.reply_text(f"â³ å‘ç° {len(urls)} ä¸ªé“¾æ¥ï¼Œæ­£åœ¨å¹¶å‘æŸ¥è¯¢...")

    # ä½¿ç”¨ä¿¡å·é‡æ‰¹é‡å¹¶å‘æ‰§è¡Œä»»åŠ¡
    semaphore = asyncio.Semaphore(MAX_CONCURRENT_REQUESTS)
    tasks = [process_sub(url, semaphore) for url in urls]
    responses = await asyncio.gather(*tasks)

    results = []
    for res in responses:
        if not res["success"]:
            results.append(f"âŒ é“¾æ¥: `{res['url']}`\nå¤±è´¥: {res['error']}")
            continue
        
        filled = min(20, int(res['percent'] / 5))
        bar = "â–ˆ" * filled + "â–‘" * (20 - filled)
        expire_date = datetime.fromtimestamp(res['expire_ts']).strftime('%Y-%m-%d') if res['expire_ts'] > 0 else "æ°¸ä¹…/æœªçŸ¥"
        
        output = (
            f"ğŸ“„ *æœºåœº*: `{res['name']}`\n"
            f"ğŸ·ï¸ *è®¢é˜…*: `{res['url']}`\n"
            f"ğŸ“Š *æµé‡*: `[{bar}] {res['percent']}%`\n"
            f"æ€»è®¡: `{format_size(res['total'])}` | å‰©ä½™: `{format_size(res['remain'])}`\n"
            f"å·²ç”¨: `{format_size(res['used'])}` (â†‘{format_size(res['upload'])} â†“{format_size(res['download'])})\n"
            f"â° *åˆ°æœŸ*: `{expire_date}`\n"
        )
        if res['node']:
            output += f"ğŸŒ *èŠ‚ç‚¹*: `{res['node']['count']}ä¸ª ({res['node']['detail']})`"
        results.append(output)

    final_text = "\n" + ("â€”"*15) + "\n\n".join(results)

    if is_txt:
        file_data = BytesIO(final_text.replace("*", "").replace("`", "").encode())
        file_data.name = f"sub_report_{int(time.time())}.txt"
        await msg.reply_document(document=file_data, caption=f"âœ… å·²å®Œæˆ {len(urls)} ä¸ªé“¾æ¥çš„æ‰¹é‡æŸ¥è¯¢")
        await status_msg.delete()
    else:
        if len(final_text) > 4000:
            final_text = final_text[:4000] + "\n\n...(å†…å®¹è¿‡é•¿ï¼Œè¯·ä½¿ç”¨ `/subinfo txt` è·å–æ–‡ä»¶æŠ¥å‘Š)"
        await status_msg.edit_text(final_text, parse_mode=constants.ParseMode.MARKDOWN, disable_web_page_preview=True)

# --- å¯åŠ¨ ---

if __name__ == "__main__":
    asyncio.run(load_remote_mappings())
    app = ApplicationBuilder().token(TOKEN).build()
    app.add_handler(CommandHandler(["subinfo", "cha"], subinfo_handler))
    print("Bot å·²å¯åŠ¨ï¼Œæ”¯æŒ TXT æ–‡ä»¶æ‰¹é‡è¯†åˆ«...")
    app.run_polling()
